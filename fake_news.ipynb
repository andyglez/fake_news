{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from math import sqrt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf(text):\n",
    "    sentences = st(text)\n",
    "    vect = TfidfVectorizer(min_df=1)\n",
    "    tfidf = vect.fit_transform(sentences)\n",
    "    matrix = np.asarray((tfidf * tfidf.T).A)\n",
    "    matrix.resize(20, 20)\n",
    "    return matrix.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_input(corpus, classes):\n",
    "    docs = [title + '. ' + text for title, text in corpus]\n",
    "    prep = [tf_idf(text) for text in docs]\n",
    "    outp = [[1, 0] if i == 'FAKE' else [0, 1] for i in classes]\n",
    "    return np.asarray(prep), np.asarray(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pos(l):\n",
    "    m = 0\n",
    "    j = 0\n",
    "    for i, n in enumerate(l):\n",
    "        if n > m:\n",
    "            j = i\n",
    "            m = n\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, real):\n",
    "    result = []\n",
    "    for p,r in zip(pred, real):\n",
    "        (i, j) = (max_pos(p), max_pos(r))\n",
    "        if i == j and r == [1,0]:\n",
    "            result.append('TP')\n",
    "        elif i == j and r == [0,1]:\n",
    "            result.append('TN')\n",
    "        elif i != j and r == [1,0]:\n",
    "            result.append('FN')\n",
    "        elif i != j and r == [0,1]:\n",
    "            result.append('FP')\n",
    "    precision = result.count('TP') / (result.count('TP') + result.count('FP'))\n",
    "    recall = result.count('TP') / (result.count('TP') + result.count('FN'))\n",
    "    f1 = 2*((precision*recall)/(precision + recall))\n",
    "    accuracy = (result.count('TP') + result.count('TN')) / (result.count('TP') + result.count('TN') + result.count('FN') + result.count('FP'))\n",
    "    msg = 'Precision: \\t' + str(precision) + '\\n'\n",
    "    msg += 'Recall: \\t' + str(recall) + '\\n'\n",
    "    msg += 'F1: \\t\\t' + str(f1) + '\\n'\n",
    "    msg += 'Accuracy: \\t' + str(accuracy)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['ID', 'TITLE', 'TEXT', 'LABEL']\n",
    "data = pd.read_csv(\"fake_or_real_news.csv\", names=cols, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(data[cols[3]]) // 2\n",
    "x_train, y_train = flat_input(list(zip(data[cols[1]], data[cols[2]]))[:k], data[cols[3]][:k])\n",
    "x_validate, y_validate = flat_input(list(zip(data[cols[1]], data[cols[2]]))[k:], data[cols[3]][k:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(units=15, activation='relu', input_dim=400))\n",
    "model.add(keras.layers.Dense(units=8, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3167/3167 [==============================] - 1s 306us/step - loss: 0.6585 - acc: 0.6113\n",
      "Epoch 2/10\n",
      "3167/3167 [==============================] - 0s 36us/step - loss: 0.6131 - acc: 0.6823\n",
      "Epoch 3/10\n",
      "3167/3167 [==============================] - 0s 35us/step - loss: 0.5973 - acc: 0.6849\n",
      "Epoch 4/10\n",
      "3167/3167 [==============================] - 0s 34us/step - loss: 0.5880 - acc: 0.7003\n",
      "Epoch 5/10\n",
      "3167/3167 [==============================] - 0s 34us/step - loss: 0.5797 - acc: 0.7026\n",
      "Epoch 6/10\n",
      "3167/3167 [==============================] - 0s 35us/step - loss: 0.5726 - acc: 0.7060\n",
      "Epoch 7/10\n",
      "3167/3167 [==============================] - 0s 32us/step - loss: 0.5662 - acc: 0.7152\n",
      "Epoch 8/10\n",
      "3167/3167 [==============================] - 0s 35us/step - loss: 0.5634 - acc: 0.7073\n",
      "Epoch 9/10\n",
      "3167/3167 [==============================] - 0s 36us/step - loss: 0.5560 - acc: 0.7187\n",
      "Epoch 10/10\n",
      "3167/3167 [==============================] - 0s 33us/step - loss: 0.5499 - acc: 0.7215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26576034a20>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3168/3168 [==============================] - 0s 122us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6065550831833271, 0.6824494949494949]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_validate, y_validate, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(x_validate, batch_size=32).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1601 / 1566'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = data[cols[3]].tolist()[:k]\n",
    "str(c.count('FAKE')) + ' / ' + str(c.count('REAL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: \t0.6761543327008223\n",
      "Recall: \t0.6839411388355726\n",
      "F1: \t\t0.6800254452926209\n",
      "Accuracy: \t0.6824494949494949\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(result, y_validate.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
